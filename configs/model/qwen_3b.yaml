# Qwen2.5-VL-3B-Instruct model configuration
name: qwen
model_id: Qwen/Qwen2.5-VL-3B-Instruct

# Quantization
use_int8: false

# Processing
use_fast_processor: true

# Layer taps
llm_layers: all  # or specify list like [0, 6, 12, 18, 24, 30, 35]

# Device
device: cuda
